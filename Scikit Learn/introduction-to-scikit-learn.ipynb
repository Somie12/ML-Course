{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b1b9338-06a7-48f2-9b2f-5ed0e6955ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3695917-491b-4cae-83bd-3aea8bb0a3aa",
   "metadata": {},
   "source": [
    "### Introductiont o Scikit-Learn (sklearn)\n",
    "\n",
    "This notebook demonstrates some of the most useful functions of the beautiful Sikit-Learn library.\n",
    "\n",
    "What we are going to cover:\n",
    "\n",
    "0. An end-to-end Scikit-Learn workflow\n",
    "1. Getting the data ready\n",
    "2. Choose the right estimator/algorithm for our problems\n",
    "3. Fit the model/algorithm and use it to make perdictions on our data\n",
    "4. Evaluating a model\n",
    "5. Imporve a model\n",
    "6. Save and load a trained model\n",
    "7. Putting it all together!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daba4350-605c-4ef4-b05d-f3b7d727e7bd",
   "metadata": {},
   "source": [
    "## 0. An end-to-end Scikit-Learn workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3942c27d-c811-4983-a698-c9206755fce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "0        0   0     1       1  \n",
       "1        0   0     2       1  \n",
       "2        2   0     2       1  \n",
       "3        2   0     2       1  \n",
       "4        2   0     2       1  \n",
       "..     ...  ..   ...     ...  \n",
       "298      1   0     3       0  \n",
       "299      1   0     3       0  \n",
       "300      1   2     3       0  \n",
       "301      1   1     3       0  \n",
       "302      1   1     2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Get the data ready\n",
    "import pandas as pd\n",
    "heart_disease = pd.read_csv(\"data/heart-disease.csv\")\n",
    "heart_disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d275120d-4f0e-4b9d-8b62-59f8d86777fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X (features matrix)\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "\n",
    "# Create y (labels)\n",
    "y = heart_disease[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98ee8066-5b56-4478-b82c-458372aca0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2226296b-98dc-427b-8cd1-7a08c47bacbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'monotonic_cst': None,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Chose the right model and hyperpaprameters\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# We'll keep the default hyperparameters\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12e01751-1e02-4fce-be01-f10ba1214ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Fir the model to the training data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a5835a4-fd41-4104-ad87-38f1a6d72ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "System:\n",
      "    python: 3.12.4 | packaged by Anaconda, Inc. | (main, Jun 18 2024, 15:03:56) [MSC v.1929 64 bit (AMD64)]\n",
      "executable: C:\\Users\\SURBHI KUMARI\\Desktop\\ML Course\\Scikit Learn\\sample_project_1\\env\\python.exe\n",
      "   machine: Windows-11-10.0.22631-SP0\n",
      "\n",
      "Python dependencies:\n",
      "      sklearn: 1.4.2\n",
      "          pip: 24.1.1\n",
      "   setuptools: 69.5.1\n",
      "        numpy: 1.26.4\n",
      "        scipy: 1.14.0\n",
      "       Cython: None\n",
      "       pandas: 2.2.2\n",
      "   matplotlib: 3.8.4\n",
      "       joblib: 1.4.2\n",
      "threadpoolctl: 3.5.0\n",
      "\n",
      "Built with OpenMP: True\n",
      "\n",
      "threadpoolctl info:\n",
      "       user_api: blas\n",
      "   internal_api: openblas\n",
      "    num_threads: 12\n",
      "         prefix: libopenblas\n",
      "       filepath: C:\\Users\\SURBHI KUMARI\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy.libs\\libopenblas64__v0.3.23-293-gc2f4bdbb-gcc_10_3_0-2bde3a66a51006b2b53eb373ff767a3f.dll\n",
      "        version: 0.3.23.dev\n",
      "threading_layer: pthreads\n",
      "   architecture: Haswell\n",
      "\n",
      "       user_api: blas\n",
      "   internal_api: openblas\n",
      "    num_threads: 12\n",
      "         prefix: libscipy_openblas\n",
      "       filepath: C:\\Users\\SURBHI KUMARI\\AppData\\Roaming\\Python\\Python312\\site-packages\\scipy.libs\\libscipy_openblas-5b1ec8b915dfb81d11cebc0788069d2d.dll\n",
      "        version: 0.3.27.dev\n",
      "threading_layer: pthreads\n",
      "   architecture: Haswell\n",
      "\n",
      "       user_api: openmp\n",
      "   internal_api: openmp\n",
      "    num_threads: 12\n",
      "         prefix: vcomp\n",
      "       filepath: C:\\Users\\SURBHI KUMARI\\Desktop\\ML Course\\Scikit Learn\\sample_project_1\\env\\vcomp140.dll\n",
      "        version: None\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.show_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7eadd55e-b51b-4217-b360-90393d66bb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train,y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c40a8b0-4547-46bf-a50c-983ca1c1002a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = clf.predict(X_test)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "520e5fce-297e-4ece-984f-1def1e921c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102    1\n",
       "165    0\n",
       "106    1\n",
       "186    0\n",
       "297    0\n",
       "      ..\n",
       "214    0\n",
       "254    0\n",
       "83     1\n",
       "300    0\n",
       "36     1\n",
       "Name: target, Length: 61, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fecfd74f-21d4-4b15-b6ca-e9d50360f2f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Evaluate the model on the training data and test data\n",
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d643d7a-1c12-4724-adfe-00b13cf64750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8360655737704918"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "598c4fa7-717d-427c-b1c7-76b5d49568f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.70      0.76        23\n",
      "           1       0.83      0.92      0.88        38\n",
      "\n",
      "    accuracy                           0.84        61\n",
      "   macro avg       0.84      0.81      0.82        61\n",
      "weighted avg       0.84      0.84      0.83        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21be83a5-3f65-4f84-bf01-f89554d8f2e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16,  7],\n",
       "       [ 3, 35]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f37d410-446b-478c-9a28-a444b80e850a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8360655737704918"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90bdf376-81c9-4264-8729-57c3fbcc4a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying model with 10 estimators...\n",
      "Model accuracy on test set: 80.327869%\n",
      "\n",
      "Trying model with 20 estimators...\n",
      "Model accuracy on test set: 83.606557%\n",
      "\n",
      "Trying model with 30 estimators...\n",
      "Model accuracy on test set: 77.049180%\n",
      "\n",
      "Trying model with 40 estimators...\n",
      "Model accuracy on test set: 81.967213%\n",
      "\n",
      "Trying model with 50 estimators...\n",
      "Model accuracy on test set: 83.606557%\n",
      "\n",
      "Trying model with 60 estimators...\n",
      "Model accuracy on test set: 81.967213%\n",
      "\n",
      "Trying model with 70 estimators...\n",
      "Model accuracy on test set: 86.885246%\n",
      "\n",
      "Trying model with 80 estimators...\n",
      "Model accuracy on test set: 85.245902%\n",
      "\n",
      "Trying model with 90 estimators...\n",
      "Model accuracy on test set: 80.327869%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Improve a model\n",
    "# Try different amount of n_estimators\n",
    "np.random.seed(42)\n",
    "for i in range(10,100,10):\n",
    "    print(f\"Trying model with {i} estimators...\")\n",
    "    clf = RandomForestClassifier(n_estimators=i).fit(X_train,y_train)\n",
    "    print(f\"Model accuracy on test set: {clf.score(X_test, y_test)*100 :2f}%\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "865c5349-0893-42bf-8c4c-0b5b30883937",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SURBHI KUMARI\\AppData\\Local\\Temp\\ipykernel_13108\\3260220933.py:4: ResourceWarning: unclosed file <_io.BufferedWriter name='random_forest_model_1.pkl'>\n",
      "  pickle.dump(clf,open(\"random_forest_model_1.pkl\",\"wb\"))\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "# 6. Save a model and load it\n",
    "import pickle\n",
    "\n",
    "pickle.dump(clf,open(\"random_forest_model_1.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "479c733a-b4c1-4480-bd0b-aefbef351137",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SURBHI KUMARI\\AppData\\Local\\Temp\\ipykernel_13108\\2030330538.py:1: ResourceWarning: unclosed file <_io.BufferedReader name='random_forest_model_1.pkl'>\n",
      "  loaded_model = pickle.load(open(\"random_forest_model_1.pkl\", \"rb\"))\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8032786885245902"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = pickle.load(open(\"random_forest_model_1.pkl\", \"rb\"))\n",
    "loaded_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84decfff-9327-4dbf-b94a-382eabbb1123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's listify the contents\n",
    "what_were_covering = [ \"0. An end-to-end Scikit-Learn workflow\",\n",
    "\"1. Getting the data ready\",\n",
    "\"2. Choose the right estimator/algorithm for our problems\",\n",
    "\"3. Fit the model/algorithm and use it to make perdictions on our data\",\n",
    "\"4. Evaluating a model\",\n",
    "\"5. Imporve a model\",\n",
    "\"6. Save and load a trained model\",\n",
    "\"7. Putting it all together!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e808ab9-3568-498a-8711-68e761f10bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0. An end-to-end Scikit-Learn workflow',\n",
       " '1. Getting the data ready',\n",
       " '2. Choose the right estimator/algorithm for our problems',\n",
       " '3. Fit the model/algorithm and use it to make perdictions on our data',\n",
       " '4. Evaluating a model',\n",
       " '5. Imporve a model',\n",
       " '6. Save and load a trained model',\n",
       " '7. Putting it all together!']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "what_were_covering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdd060e-70a9-414b-abaf-ac63ee839847",
   "metadata": {},
   "source": [
    "### 1. Getting our data ready to be used with machine learning\n",
    "\n",
    "Three things we have to do:\n",
    "   1. Split the data into features and labels (usually 'X' and 'y')\n",
    "   2. Filling (also called imputing) or disregarding missing values\n",
    "   3. Converting non-numerical values to numerical values (also called feature encoding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3b5a72d-d54b-4497-aae5-e88f64b80414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f83dcb6d-e07a-49d1-ae3b-35cfc7904214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  \n",
       "0   0     1  \n",
       "1   0     2  \n",
       "2   0     2  \n",
       "3   0     2  \n",
       "4   0     2  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = heart_disease.drop(\"target\",axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c42cc0c-ce72-436d-9966-faa3e69f9789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = heart_disease[\"target\"]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92438416-7298-4fae-a10f-21fbe0f5af5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dcadf782-6f8f-42a5-afc6-3b2af15cd2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((242, 13), (61, 13), (242,), (61,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1565214-b6e0-4692-861f-e09a6ff42802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 13)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b68a314d-e3e6-4591-9521-85f81283ee69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242.4"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[0] * 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17c57c9c-9513-4c68-afed-e6e6254b1085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(heart_disease)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc501d1-8136-469b-b0b9-797ce2478110",
   "metadata": {},
   "source": [
    "### 1.1 Make sure it's all numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88ea441e-1d52-4175-acc8-095f5767f951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431</td>\n",
       "      <td>4</td>\n",
       "      <td>15323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714</td>\n",
       "      <td>5</td>\n",
       "      <td>19943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714</td>\n",
       "      <td>4</td>\n",
       "      <td>28343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365</td>\n",
       "      <td>4</td>\n",
       "      <td>13434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577</td>\n",
       "      <td>3</td>\n",
       "      <td>14043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Make Colour  Odometer (KM)  Doors  Price\n",
       "0   Honda  White          35431      4  15323\n",
       "1     BMW   Blue         192714      5  19943\n",
       "2   Honda  White          84714      4  28343\n",
       "3  Toyota  White         154365      4  13434\n",
       "4  Nissan   Blue         181577      3  14043"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales = pd.read_csv(\"data/car-sales-extended.csv\")\n",
    "car_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77a6ed1b-61df-41c8-aa55-f4a8e35c545a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Doors\n",
       "4    856\n",
       "5     79\n",
       "3     65\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales[\"Doors\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1f71292-ab7d-4cb0-915e-149d2283f0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(car_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1debd50-e799-4195-ae51-2455a5824399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             object\n",
       "Colour           object\n",
       "Odometer (KM)     int64\n",
       "Doors             int64\n",
       "Price             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "05504ac2-1e1b-4dfd-9de5-fd5da02a6ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into X/y\n",
    "X = car_sales.drop(\"Price\", axis=1)\n",
    "y = car_sales[\"Price\"]\n",
    "\n",
    "# Split into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b42040b4-9334-4e65-8fd5-4c4a5336e640",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Toyota'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13108\\608098312.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Build machine learning model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\ML Course\\Scikit Learn\\sample_project_1\\env\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m                 skip_parameter_validation=(\n\u001b[0;32m   1471\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1472\u001b[0m                 \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1473\u001b[0m             \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1474\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\ML Course\\Scikit Learn\\sample_project_1\\env\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[1;31m# Validate or convert input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         X, y = self._validate_data(\n\u001b[0m\u001b[0;32m    364\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m             \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\ML Course\\Scikit Learn\\sample_project_1\\env\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    646\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m\"estimator\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m                     \u001b[0mcheck_y_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 650\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    651\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ensure_2d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\ML Course\\Scikit Learn\\sample_project_1\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1259\u001b[0m         raise ValueError(\n\u001b[0;32m   1260\u001b[0m             \u001b[1;33mf\"\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mestimator_name\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m requires y to be passed, but the target y is None\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1261\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1263\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m   1264\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1266\u001b[0m         \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\ML Course\\Scikit Learn\\sample_project_1\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    994\u001b[0m                         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    995\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    997\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 998\u001b[1;33m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    999\u001b[0m                 raise ValueError(\n\u001b[0;32m   1000\u001b[0m                     \u001b[1;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m                 \u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\ML Course\\Scikit Learn\\sample_project_1\\env\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[1;31m# Use NumPy API to support order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m         \u001b[1;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m         \u001b[1;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m   2149\u001b[0m     def __array__(\n\u001b[0;32m   2150\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2151\u001b[0m     \u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2153\u001b[1;33m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2154\u001b[0m         if (\n\u001b[0;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2156\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Toyota'"
     ]
    }
   ],
   "source": [
    "# Build machine learning model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdad25ca-c46b-4d30-b64c-e7b1f82df2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the categories into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer ([(\"one_hot\",\n",
    "                                   one_hot,\n",
    "                                   categorical_features)],\n",
    "                                 remainder=\"passthrough\")\n",
    "\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29123f42-a3e1-4204-bc2d-8546ec80676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(transformed_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44267ca8-7d16-4761-b6ab-422144fa56ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(car_sales[[\"Make\",\"Colour\",\"Doors\"]])\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b57e0d7-da97-4ae3-a7df-91a8025e35d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's refit the model\n",
    "np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X,\n",
    "                                                   y,\n",
    "                                                   test_size = 0.2)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e5e923-d315-4bf0-86a1-b83b96362d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ab0c96-9dff-4b15-bfe9-5b486ecd24a1",
   "metadata": {},
   "source": [
    "### 1.2 What if there wer missing values?\n",
    "\n",
    "1. Fill them with some value (also known as imputation).\n",
    "2. Remove the samples with missing data altogether. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3181f454-dc55-489d-b13b-a0d811136ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import car sales missing data\n",
    "car_sales_missing = pd.read_csv(\"data/car-sales-extended-missing-data.csv\")\n",
    "car_sales_missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30748e18-237c-4041-a045-7de72fc717ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1c5284-05b2-48d1-b40d-faf28bfbee45",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = car_sales_missing.drop(\"Price\", axis=1)\n",
    "y = car_sales_missing[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67e5ecc-e196-44f5-acf1-a0ade5c173ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try and convert our data to numbers\n",
    "# Turn the categories into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer ([(\"one_hot\",\n",
    "                                   one_hot,\n",
    "                                   categorical_features)],\n",
    "                                 remainder=\"passthrough\")\n",
    "\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6b0ac0-de35-4eae-ba66-b44a04d459db",
   "metadata": {},
   "source": [
    "#### Option 1: Fill missing data with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039e8a6a-1162-471c-ad48-b63edc663934",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing[\"Doors\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a38f9ac-b8e8-4765-8d29-98ff801b5c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the \"Make\" column\n",
    "car_sales_missing[\"Make\"].fillna(\"missing\",inplace=True)\n",
    "\n",
    "# Fill the \"Colour\" column\n",
    "car_sales_missing[\"Colour\"].fillna(\"missing\",inplace = True)\n",
    "\n",
    "# Fill the \"Odometer (KM)\" column\n",
    "car_sales_missing[\"Odometer (KM)\"].fillna(car_sales_missing[\"Odometer (KM)\"].mean(), inplace=True)\n",
    "\n",
    "# Fill the \"Doors\" column\n",
    "car_sales_missing[\"Doors\"].fillna(4, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8b63e9-b511-4a9e-9e7f-6e4965b6b910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check our dataframe again\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e563179-7249-4782-bc70-4dabccc7973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing Price value\n",
    "car_sales_missing.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a7e61a-7889-4f82-a9cb-c51e4ba7828c",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84463346-f4b1-4ee3-b3c7-9d9b9fa9686d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(car_sales_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bda4e6-3a53-4d57-9ced-fab9327db974",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = car_sales_missing.drop(\"Price\", axis=1)\n",
    "y = car_sales_missing[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dc193c-5a2d-4258-8f3c-514854fc9a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try and convert our data to numbers\n",
    "# Turn the categories into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer ([(\"one_hot\",\n",
    "                                   one_hot,\n",
    "                                   categorical_features)],\n",
    "                                 remainder=\"passthrough\")\n",
    "\n",
    "transformed_X = transformer.fit_transform(car_sales_missing)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39845aa5-e865-43c1-a155-3420cb24380c",
   "metadata": {},
   "source": [
    "### Option 2: Fill missing values with Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f1c71d-b70b-4f96-890f-4414e4f93fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing = pd.read_csv(\"data/car-sales-extended-missing-data.csv\")\n",
    "car_sales_missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd4c9db-445d-4697-9df7-5199d97aaf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7d1efe-3314-429d-a9fa-491ed2483aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows with no labels\n",
    "car_sales_missing.dropna(subset=[\"Price\"],inplace=True)\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92b70b6-8237-452a-bb29-c67fde05aba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into X & y\n",
    "X = car_sales_missing.drop(\"Price\",axis=1)\n",
    "y = car_sales_missing[\"Price\"]\n",
    "\n",
    "# Split data into train and test\n",
    "np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d817c649-8280-4f84-a2ef-8b31db5273cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacb08e1-15cd-42eb-a7ca-94ce97b4ddf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with Scikit-Learn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Fill categorical values with 'missing' & numerical values with mean\n",
    "cat_imputer = SimpleImputer(strategy=\"constant\", fill_value=\"missing\")\n",
    "door_imputer = SimpleImputer(strategy=\"constant\",fill_value=4)\n",
    "num_imputer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "# Define columns\n",
    "cat_features = [\"Make\", \"Colour\"]\n",
    "door_feature = [\"Doors\"]\n",
    "num_features = [\"Odometer (KM)\"]\n",
    "\n",
    "# Create an imputer (something that fills missing data)\n",
    "imputer = ColumnTransformer([\n",
    "    (\"cat_imputer\", cat_imputer, cat_features),\n",
    "    (\"door_imputer\", door_imputer, door_feature),\n",
    "    (\"num_imputer\", num_imputer, num_features)\n",
    "])\n",
    "\n",
    "# Fill train and test values separately\n",
    "filled_X_train = imputer.fit_transform(X_train)\n",
    "filled_X_test = imputer.transform(X_test)\n",
    "\n",
    "# Check filled X_train\n",
    "filled_X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159393fe-a21b-4607-9026-15cb236c0d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get our transformed data array's back into DataFrame's\n",
    "car_sales_filled_train = pd.DataFrame(filled_X_train, \n",
    "                                      columns=[\"Make\", \"Colour\", \"Doors\", \"Odometer (KM)\"])\n",
    "\n",
    "car_sales_filled_test = pd.DataFrame(filled_X_test, \n",
    "                                     columns=[\"Make\", \"Colour\", \"Doors\", \"Odometer (KM)\"])\n",
    "\n",
    "# Check missing data in training set\n",
    "car_sales_filled_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01060d22-674c-445a-bd82-d8452050fc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see the original... still missing values\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91459086-b2b7-4a49-ac4d-9a440f88e1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try and convert our data to numbers\n",
    "# Turn the categories into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer ([(\"one_hot\",\n",
    "                                   one_hot,\n",
    "                                   categorical_features)],\n",
    "                                 remainder=\"passthrough\")\n",
    "\n",
    "# Fill train and test values separately\n",
    "transformed_X_train = transformer.fit_transform(car_sales_filled_train)\n",
    "transformed_X_test = transformer.transform(car_sales_filled_test)\n",
    "\n",
    "# Check transformed and filled X_train\n",
    "transformed_X_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd3aed3-41fb-4bbd-94dc-8fe63f382320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we've got out data as numbers and filled (no missing values)\n",
    "# Let's fit a model\n",
    "np.random.seed(42)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# Make sure to use transformed (filled and one-hot encoded X data)\n",
    "model.fit(transformed_X_train, y_train)\n",
    "model.score(transformed_X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99fe975-b14b-4850-9442-2e789a4f1583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check length of transformed data (filled and one-hot encoded)\n",
    "# vs. length of original data\n",
    "len(transformed_X_train.toarray())+len(transformed_X_test.toarray()), len(car_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1027d1-3da8-4b24-8499-93422d35219d",
   "metadata": {},
   "source": [
    "## 2. Choosing the right estimator/algorithm for your problem\n",
    "\n",
    "Some things to note:\n",
    "\n",
    "* Sklearn refers to machine learning models, algorithms as estimators.\n",
    "* Classification problem - perdicting a category (heart disease or not)\n",
    "  * Sometimes you'll see `clf` (short for classifier) used as a classification estimator\n",
    "* Regression problem - perdicting a number (selling price of a car)\n",
    "\n",
    "\n",
    "If you're working on a machine learning problem and looking to use Sklearn and not sure what model you should use, refer to the sklearn machine learning map: https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be939061-bba8-45b6-88bb-09dd4a2ed47e",
   "metadata": {},
   "source": [
    "### 2.1 Picking a machine learning model for a regression problem\n",
    "\n",
    "Let's use the California Housing dataset - https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fcc95b-77fc-4a3f-be77-7bb417b3dc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get California Housing dataset\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d04aba-712c-431d-9ed4-b97dc926d3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df = pd.DataFrame(housing[\"data\"], columns=housing[\"feature_names\"])\n",
    "housing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae216fe-048c-4956-89da-45ab95c6862e",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df[\"target\"] = housing[\"target\"]\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4d01e3-be19-4f3b-a731-ef9f47c9a89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df = housing_df.drop(\"MedHouseVal\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4feee2c-15c0-4661-9f2b-f8655b412a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c1f6aa-6d83-4b10-a765-ffe0b42ddf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import algorithm/estimator\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"] # median house price in $ 100,00s\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2)\n",
    "\n",
    "# Instantiate and fit the model (on the training set)\n",
    "model = Ridge()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Check the score of the model (on the test set)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f70903-a090-45ea-befa-1230d07b0d59",
   "metadata": {},
   "source": [
    "What if `Ridge` didn't work or the score didn't fit our needs?\n",
    "\n",
    "Well, we could always try a different model...\n",
    "\n",
    "How about we try an ensemble model (an ensemble is combination of smaller models to try and make better predictions than just a single model)?\r\n",
    "\r\n",
    "Sklearn's ensemble models can be found here: https://scikit-learn.org/stable/modules/ensemble.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c1dedd-f8ea-41bb-a53b-ca450b45a677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RandomForestRegressor model class from the ensemble module\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "X = housing_df.drop(\"target\",axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "# Create random forest model\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Check the score of the model (on the test set)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f09c82-35f0-4266-be2b-3f7b4212f03a",
   "metadata": {},
   "source": [
    "## 2.2 Picking a machine learning model for a classification problem\n",
    "\n",
    "Let's go to the map... https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0180bcc8-1552-412e-8ec3-1fad9b2cb5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease = pd.read_csv(\"data/heart-disease.csv\")\n",
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0dbe23-241f-4fb0-bfee-410eb8ca1a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(heart_disease)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e579958-7afb-4369-963f-8d776c55c12b",
   "metadata": {},
   "source": [
    "Consulting the map and it says to try `LinearSVC`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7490be-fc0e-457f-aba5-16a777e02e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the LinearSVC estimator class\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make the data\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.2)\n",
    "\n",
    "# Instantiate LinearSVC\n",
    "clf = LinearSVC(max_iter = 10000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the LinearSVC\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cdc337-ab40-4546-9b4c-2029d863fd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a811b1c7-2a2d-4a3d-870a-5c56981f17f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RandomForestClassifier estimator class\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make the data\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.2)\n",
    "\n",
    "# Instantiate RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the Random Forest Classifier\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a413fdbd-59ec-485b-aef8-722f439f2aa7",
   "metadata": {},
   "source": [
    "Tidbit: \n",
    "\n",
    "    1. If you have structured data, use ensemble methods\n",
    "    2. If you have unstructured data, use deep learning or transfer learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a869107-dceb-4657-90df-24a636720dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d55e89b-1605-4e45-afeb-95dd5b259e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "what_were_covering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4cd4c4-5ad1-434b-b20b-78dd4ccfc215",
   "metadata": {},
   "source": [
    "### 3. Fit the model/algorithm on our data and use it to make perdictions\n",
    "\n",
    "### 3.1 Fitting the model to the data\n",
    "\n",
    "Different names for:\n",
    "* `X` = features, features variables, data\n",
    "* `y` = labels, targets, target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d952d58-2228-4e2b-bb63-c5081266150a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RandomForestClassifier estimator class\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make the data\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.2)\n",
    "\n",
    "# Instantiate RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Fit the model to the data (training the machine learning model)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the Random Forest Classifier (use the patterns the model has learned)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09126505-c2f0-474e-97f2-96d2e381b5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a3b953-c36d-4080-a952-bbc49c8042a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cafe4ce-b653-490e-925c-ab74a0fc96a0",
   "metadata": {},
   "source": [
    "### Random Forest Deep Dive\n",
    "\n",
    "These resources will help you understand what's happening inside the Random Forest models we've been using.\n",
    "\n",
    "   1. Random Forest Wikipedia\r",
    "   2. \n",
    "Random Forest Wikipedia (simple version\n",
    "   3. \r\n",
    "Random Forests in Python by yha   4. t\r\n",
    "An Implementation and Explanation of the Random Forest in Python by Will Koehrsen\n",
    "\n",
    "### 3.2 Make perdictions using a machine learning\n",
    "\n",
    "2 ways to make perdictions:\n",
    "1. `perdict()`\n",
    "2. `perdict_proba()` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27734c9b-3421-4d4f-ab4b-e0425c713876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a trained model to make perdictions\n",
    "clf.predict(np.array([1,7,8,3,4])) # this doesn't work...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b922ddc7-d428-4789-accf-7bd5682c2c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707f79ea-4f84-4982-b748-8920fb381d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafd9493-90cf-4447-ac33-372432b05e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02187ae8-46c5-417f-963e-8a0df9f38f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare perdictions to truth labels to evaluate the model\n",
    "y_preds = clf.predict(X_test)\n",
    "np.mean(y_preds == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d9076b-f35a-4239-8866-0de7af6b5b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b601b12e-858d-4a98-b3e3-ecfa836b4995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192050bd-6ec6-4702-b256-ca231f3f405f",
   "metadata": {},
   "source": [
    "Make predictions with perdict_proba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db286ea-07ac-42bf-a991-a0b827ffb5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_proba() returns probablities of a classification label\n",
    "clf.predict_proba(X_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4089b713-87aa-4308-b0c7-b08d6df4ebe9",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Let's predict() on the same data...\n",
    "clf.predict(X_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b886258a-f2df-4008-825c-7ee3574f18ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a911c842-7203-462b-a564-cd5b9f4c1b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5f87a5-5975-4c08-bcd7-d6dc8227c608",
   "metadata": {},
   "source": [
    "`perdict()` can also be used for regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c7a6d2-dc99-480c-8c25-2ddd0fa6064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76e65a3-d8d8-4799-b5ba-dcb5f2e87cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "# Create model instance\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ff3025-80bc-433c-971f-c5e8f059de95",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5805ea71-49f8-48af-8e07-aeffbdad5e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8692645-4c4f-42b0-8ffa-8af461f966c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca96da7e-3de9-46cb-9520-350837bba12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3122ab8-e764-4dfe-93da-40cbddb21b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the predictions to the truth \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b81b1e-a899-4a02-8f3c-a71c5d110f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a04422c-7a53-4296-ac80-5ddf45f24fd5",
   "metadata": {},
   "source": [
    "### Evaluating  a machine learning model\n",
    "\n",
    "Three ways to evaluate Scikit-Learn models/estiamtors:\n",
    "   1. Estimator's built-in `score()` method\n",
    "   2. The `scoring` parameter\n",
    "   3. Problem-specific metric functions\n",
    "\n",
    "You can read more about these here: https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fa19a3-bcec-44d7-9b45-2609a16c6aa1",
   "metadata": {},
   "source": [
    "### 4.1 Evaluating a model with the `score` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a810e6f-1b74-46de-a530-76018d7fa357",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make the data\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.2)\n",
    "\n",
    "# Instantiate RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "# Fit the model to the data (training the machine learning model)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5132876e-eaf4-43ad-be24-0dfa4a0db507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The highest value for the .score() method is 1.0, the lowest is 0.0\n",
    "clf.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3da524-0e05-4cee-acb7-32accced7bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa51643c-7b2b-4a92-98f6-d215d5c27edb",
   "metadata": {},
   "source": [
    "Let's use the `score` method on our regression problem..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c6c412-a8b0-4978-848f-eaaf07cef644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "# Create model instance\n",
    "model = RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea5f6de-be6b-48f0-a85d-3f6ebb959dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default score() evaluation metric is r_squared fro regressiona lgorithms\n",
    "# Highest = 1.0, lowest = 0.0\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a8d1fa-70b7-47fe-8f70-96a45b356826",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e974a6b-8a28-4d1e-98a3-38e3e7107286",
   "metadata": {},
   "source": [
    " ### 4.2 Evluating a model using the `scoring` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5921268a-ec55-4849-8591-6b12de63aa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make the data\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.2)\n",
    "\n",
    "# Instantiate RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Fit the model to the data (training the machine learning model)\n",
    "clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a2b179-18f2-4d11-a476-82ffde4d5dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8688417b-c2c7-4f1a-95da-5c7d62445ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(clf, X,y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d4f7d8-a968-413c-aad7-49c194452ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Single training and test split score\n",
    "clf_single_score = clf.score(X_test, y_test)\n",
    "\n",
    "# Take the mean of 5-fold cross-validation score\n",
    "clf_cross_val_score = np.mean(cross_val_score(clf, X, y, cv=5))\n",
    "\n",
    "# Compare the two \n",
    "clf_single_score, clf_cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ec783e-b141-45b6-87f5-a1e4d57e558d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default scoirng parameter of classifier = mean accuracy\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4065f8db-64b6-458a-9773-ad7587cb413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring parameter set to None by default\n",
    "cross_val_score(clf, X, y, cv=5, scoring=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9a50cc-3cf8-44d2-892a-97f3aa48d6a0",
   "metadata": {},
   "source": [
    "### 4.2.1 Classification model evaluation metrics\n",
    "\n",
    "1. Accuracy\n",
    "2. Area under ROC curve\n",
    "3. Confusion matrix\n",
    "4. Classification report\n",
    "\n",
    "**Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bf7457-8aa3-4a34-bcda-2b36e99a5697",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af52a4c-a090-4d06-a75c-4e5d0fc4bdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "cross_val_score = cross_val_score(clf, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c89e7c-d14d-4933-b468-63f0a247369e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cross_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92c56c7-55fd-4eb1-814a-ca580fe946e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Heart Disease Classifier Cross Validated Accuracy: {np.mean(cross_val_score) *100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe458d7-2d9d-4f41-b688-1375909fbc1b",
   "metadata": {},
   "source": [
    "**Area under the reciever characteristic curve (AUC/ROC)**\n",
    "\n",
    "* Area under the curve (AUC)\n",
    "* ROC curve\n",
    "\n",
    "ROC curves are a comparison of a model's true positvie rate (tpr) versus a model false postive rate (fpr)\n",
    "\n",
    "* Ture psotive = model perdicts 1 when truth is 1\n",
    "* False postive = model perdicts 1 when truth is 0\n",
    "* True negative = model perdicts 0 when truth is 0\n",
    "* False negative = model perdicts 0 when truth is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac562ba-88d5-435d-a4f3-85e1552e7650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X_test.....etc\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9555c7-80ca-4596-909b-5fc25309df94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Fit the classifier\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "# Make perdictions with probablities\n",
    "y_probs = clf.predict_proba(X_test)\n",
    "\n",
    "y_probs[:10], len(y_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c9cabf-5ba6-4278-a878-1590a481bc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs_positive = y_probs[:,1]\n",
    "y_probs_positive[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a172e7-f5a9-4634-9760-fbf9b602ee9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate fpr, tpr and thresholds\n",
    "fpr, tpr, thresholds = roc_curve (y_test, y_probs_positive)\n",
    "\n",
    "# Check the false postive rates\n",
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04625c6a-adb0-4c3a-9dd3-b33dd2c9e705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function for plotting ROC curves\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(fpr,tpr):\n",
    "    \"\"\"\n",
    "    Plots a ROC curve given the false postive rate (fpr)\n",
    "    and true postive rate (tpr) of a model.\n",
    "\n",
    "    \"\"\"\n",
    "    # Plot roc curve\n",
    "    plt.plot(fpr,tpr,color=\"orange\",label=\"ROC\")\n",
    "    # Plot line with no predictive power (baseline)\n",
    "    plt.plot([0,1],[0,1],color=\"darkblue\",linestyle=\"--\",label=\"Guessing\")\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.xlabel(\"False psotive rate (fpr)\")\n",
    "    plt.ylabel(\"True psotive rate (tpr)\")\n",
    "    plt.title(\"Reciever Operating Characteristic (ROC) Curve\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_roc_curve(fpr, tpr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3745aa-56b8-4e28-b5be-d299f4baeb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test, y_probs_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a685e2b2-3ae3-46d7-896f-d928d8698b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot perfect ROC curve and AUC score\n",
    "fpr,tpr,thresholds = roc_curve(y_test,y_test)\n",
    "plot_roc_curve(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94aeac9-36ab-4d03-81e8-974d0d404b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfect AUC Score\n",
    "roc_auc_score(y_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ba8346-4f2c-4b34-be52-39b4a6608907",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "\n",
    "The next way to evaluate a classification model is by using a confusion matrix.\n",
    "\n",
    "A confusion matrix is a quick way to compare the labels a model predicts and the actual labels it was supposed to predict. \n",
    "\n",
    "In essence, giving you an idea of where the model is getting confused. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75189bd5-93f7-491b-9398-e229e01ac117",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482aca22-c9b9-42b2-a1bc-b79c397a0caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confusion matrix with pd.crosstab()\n",
    "pd.crosstab(y_test,\n",
    "            y_preds,\n",
    "            rownames=[\"Actual Label\"],\n",
    "            colnames=[\"Predicted Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561f7794-6884-457e-bc08-a177d204292c",
   "metadata": {},
   "outputs": [],
   "source": [
    "22 + 5 + 7 + 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0536ff24-11d0-47f0-8a39-6cfeb0c9ccd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973c181b-26ec-40a6-92f8-506806d88131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to install a conda package into the current enviroment from a Jupyter Notebook\n",
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60734adc-28cc-4cb8-9711-6efdb061ff74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make our confusion matrix more visual with Seaborn's heatmap()\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the font scale\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "# Create a confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, y_preds)\n",
    "\n",
    "# Plot it using Seaborn\n",
    "sns.heatmap(conf_mat);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802eeae6-865c-44f6-a96a-6d7b74d575cf",
   "metadata": {},
   "source": [
    "### Creating a confusion matrix using Scikit-Learn\n",
    "\n",
    "Scikit-Learn has multiple different implementations of plotting confusion matrices:\n",
    "\n",
    "1. `sklearn.metrics.ConfusionMatrixDisplay.from_estimators(estimator,X,y)` - this takes a fitted estimator (like our `clf` model), features (`X`) and labels (`y`), it then uses the trained estimator to make predictions on `X` and compares the predicitions to `y` by displaying a confusion matrix.\n",
    "2. `sklearn.metrics.ConfusionMatrixDisplay.from_prediction(y_true, y_pred)` - this takes truth labels and predicted labels and compares them by displaying a confusion matrix.\n",
    "\n",
    "*Note:* Both of these methods/classes require Scikit-Learn 1.0+. To check your version of Scikit-Learn run:\n",
    "\n",
    "import sklearn\n",
    "sklearn._version_\n",
    "\n",
    "If you don't have 1.0+, you can upgrade at:  https://scikit-learn.org/stable/install.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef33303a-aeed-405a-bba4-852ccfa4c391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea55941-a68f-485f-a57c-3d7ce0eae15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d66e1c0-7c8a-4b12-88bc-f34028d6902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(estimator=clf, X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab794734-6556-42d9-9f21-94eacc87d2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_true=y_test,\n",
    "                                        y_pred=y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70029941-4cb3-4f4b-92ef-1b5b12a395b4",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa63b62-ffac-4a66-8377-73b51f9d2d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0c6003-e309-475a-be77-5274628a4957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where precision and recall become valuabale\n",
    "disease_true = np.zeros(10000)\n",
    "disease_true[0] = 1 # only one postive case\n",
    "\n",
    "disease_preds = np.zeros(10000) # model predicts every case as 0\n",
    "\n",
    "pd.DataFrame(classification_report(disease_true,\n",
    "                                   disease_preds,\n",
    "                                   output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd6a479-1299-41f9-bb07-8effc9bd4fd1",
   "metadata": {},
   "source": [
    "### Regression model evaluation metrics\n",
    "\n",
    "Model evaluation metrics documentation -  https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics\n",
    "\n",
    "The ones we're going to cover are:\n",
    "1. R^2 (pronounced r-squared) or coefficient of determination\n",
    "2. Mean absolute error (MAE)\n",
    "3. Mean squared error (MSE)\n",
    "\n",
    " **R^2**\n",
    " \n",
    "What R-squared does: Compares your models predictions to the mean of the targets. Values can range from negative infinity (a very poor model) to 1. For example, if all your model does is predict the mean of the targets, it's R^2 value would be 0. And if your model perfectly predicts a range of numbers it's R^2 value would be 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b38014-868c-4d10-b3c0-b5bdb2e0d459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7729ed-e44f-4376-92c7-dd36ffb465aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c584b8a-692a-4501-b354-cdf5970832df",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d49127-da80-46cc-a7bc-3f4608845149",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1698b6-035d-4e2f-a1a9-080bf7d46680",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c440eaeb-2367-42da-8c3e-5365f5970897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Fill an array with y_test mean\n",
    "y_test_mean = np.full(len(y_test), y_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14d1295-a929-4f09-a9ba-a1853e21d754",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_mean[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef61580-78d2-486d-9824-55b08801cd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_true = y_test,\n",
    "         y_pred = y_test_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761b740a-daee-4bce-93c7-2676a5fef162",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_true = y_test,\n",
    "         y_pred = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dcea59-6a33-414e-b81c-120acb245fc8",
   "metadata": {},
   "source": [
    "**Mean absolute error (MAE)**\n",
    "\n",
    "MAE is the average of the absolute differences between predictions and actual values.\n",
    "\n",
    "It gives you an idea of how wrong your models predictions are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4714f22b-f48c-4f3d-be5c-6200a66d6d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_preds = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_preds)\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e0b818-355c-4eeb-b49f-0d3b673ec058",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8930b37-a23c-4e79-89f6-f1961bbb4204",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2691d29-05eb-4d39-a1e6-1ab170c964b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = {\"actual values\":y_test,\n",
    "                          \"predicted values\":y_preds})\n",
    "df[\"differences\"] = df[\"predicted values\"] - df[\"actual values\"]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2154cd56-12ec-4604-ae3a-89e055722d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"differences\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8228abb-a399-42ad-94f3-8bef4974014a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE using formulas and differences\n",
    "np.abs(df[\"differences\"]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aabe008-3061-429a-9376-e7b803dd9e60",
   "metadata": {},
   "source": [
    "**Mean squared error (MSE)**\n",
    "\n",
    "MSE is the mean of the square of the errors between actual and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f366ccf6-7ce7-480e-ad1c-61cf8743ffb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean squared error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_preds = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_preds)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d72da15-e0c4-485b-b483-b4d18a20c42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"squared_differences\"] = np.square(df[\"differences\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613b0e67-2049-48a7-bc45-0176431219a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE by hand\n",
    "squared = np.square(df[\"differences\"])\n",
    "squared.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad83d9f7-e8ab-4af7-b9f4-aa191dfeb41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_large_error = df.copy()\n",
    "df_large_error.iloc[0][\"squared_difference\"] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e7e25b-e1ec-40d7-b706-63264f2d2ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_large_error.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbd440c-2fb2-4105-8690-d1244dfc0af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE with large error\n",
    "df_large_error[\"squared_differences\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495f3518-8264-4967-85dc-4dcf4c10e394",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_large_error.iloc[1:100] = 20\n",
    "df_large_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cf943f-5f46-462e-8e84-779aa2d31c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE with large error\n",
    "df_large_error[\"squared_differences\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffa5e42-0dfe-4646-8f6b-80a753edff25",
   "metadata": {},
   "source": [
    "### 4.2.3 Finally using the `scoring` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aecfc6e-4d89-4697-a6df-3bbf1ba91b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heart_disease.drop(\"target\", axis =1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd5ffe1-a6c5-44ed-b1c0-8a67712c31f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Cross-validation accuracy\n",
    "cv_acc = cross_val_score(clf, X, y, cv=5, scoring=None) # if scoring=None, estimator's default scoring evaluation emtric is used (accuracy for classification models)\n",
    "cv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f174b7-53cd-474e-b7fe-054f06856c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validated accuracy\n",
    "print(f\"The cross-validated accuracy is: {np.mean(cv_acc)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a7e327-ee2a-4ef1-892f-033c573ce331",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "cv_acc = cross_val_score(clf, X, y, cv=5, scoring=\"accuracy\")\n",
    "cv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74fb556-61db-4fe6-89d8-e0b785c99585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validated accuracy\n",
    "print(f\"The cross-validated accuracy is: {np.mean(cv_acc)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec71585b-3936-4c5f-9244-f3d27095f6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision\n",
    "cv_precision = cross_val_score(clf, X,y, cv=5, scoring=\"precision\")\n",
    "cv_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dd7bb8-8e4f-4a8b-867b-087a4b4c54b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validated precison\n",
    "print(f\"The cross-validated precision is: {np.mean(cv_precision)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78751f6-b609-4f6c-a8a9-e073f2286f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall\n",
    "np.random.seed(42)\n",
    "cv_recall = cross_val_score(clf, X, y, cv=5, scoring=\"recall\")\n",
    "cv_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f69f7a5-dd93-465e-b5d4-1a05f7efb4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validated recall\n",
    "print(f\"The cross-validated recall is: {np.mean(cv_precision)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64139259-2403-4599-8ed4-5e31efddf02a",
   "metadata": {},
   "source": [
    "Let's see the `scoring` parameter beign used for a regression problem..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a36b11-7569-4340-a52a-04d5a8e51741",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = housing_df.drop(\"target\",axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f510e0-dff4-4812-a219-427873ab2934",
   "metadata": {},
   "source": [
    "np.random.seed(42)\n",
    "cv_r2 = cross_val_score(model, X, y, cv=3, scoring=None)\n",
    "np.mean(cv_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e0d4af-6558-4858-8b57-3e41912b1c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd93e4f-ada9-4509-bc9c-cca397c96425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean squared error\n",
    "cv_mse = cross_val_score(model, X, y, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "np.mean(cv_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16d4f1f-c58c-44cc-8655-f2dec64a23c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3db522-aa62-4a9f-b0fc-750740bb8856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean absolute error\n",
    "cv_mae = cross_val_score(model, X, y, cv=5, scoring=\"neg_mean_absolute_error\")\n",
    "np.mean(cv_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48297f14-7984-4c61-b7df-1e61d6341cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e48235-f290-4311-9ef4-a67c3ecf9cd6",
   "metadata": {},
   "source": [
    "### 4.3 Using different evaluation metrics as Scikit-Learn functions\n",
    "\n",
    "The 3rd way to evaluate scikit-learn machine learning models/estimators is to use the `skelarn.metrics` module - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd5de68-3475-4f36-b9f9-c67a166746ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create X & y\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "# Create model\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make perdictions\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Evaluate model using evaluation functions\n",
    "print(\"Classifier metrics on the test set\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_preds)*100:2f}%\")\n",
    "print(f\"Precision: {precision_score(y_test, y_preds)}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_preds)}\")\n",
    "print(f\"F1: {f1_score(y_test, y_preds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe45cde4-10ff-4213-9647-9dbabca9611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create X & y\n",
    "X = housing_df.drop(\"target\",axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)\n",
    "\n",
    "# Create model \n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# Fit model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_preds = model.predict(X_test)\n",
    "\n",
    "# Evaluate model using evaluation functions\n",
    "print(\"Regression metrics on the test set\")\n",
    "print(f\"R2 score: {r2_score(y_test, y_preds)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_preds)}\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c54694-4988-4c8b-9b16-af296f2581c8",
   "metadata": {},
   "source": [
    "### 5.Improving a model\n",
    "\n",
    "First predictions = baseline predictions.\n",
    "First model = baseline model\n",
    "\n",
    "From a data perspective:\n",
    "* Could we collect more data? (generally, the more data, the better)\n",
    "* Could we improve our data?\n",
    "\n",
    "From a model perspective: \n",
    "* Is there a better model we could use?\n",
    "* Could we improve the current model?\n",
    "  \n",
    "Hyperparameters vs. Parameters\n",
    "* Parameters = model find the patterns in data\n",
    "* Hyperparameters = settings on a model you can adjust to (Potentially) improve its ability to find patterns\n",
    "\n",
    "Three ways to adjust hyperparameters\n",
    "1. By hand\n",
    "2. Randomly with RandomSEarchCV\n",
    "3. Exhaustively with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7313d14-d241-46f4-8362-f8da94b60099",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b706fe0-1373-4bcb-adea-618ef779049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e5cb05-292f-49d9-a655-9316293c0af9",
   "metadata": {},
   "source": [
    "### 5.1 Tuning hyperparameters by hand\n",
    "\n",
    "Let's make 3 sets: training , validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbb3608-3175-4752-be39-586264de072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea3433f-9f02-4413-8055-6025ebd5eed5",
   "metadata": {},
   "source": [
    "We're going to try and adjust: \n",
    "\n",
    "* `max_depth`\n",
    "* `max_features`\n",
    "* `min_sample_leaf`\n",
    "* `min_sample_split`\n",
    "* `n_estimators`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a1612e-ae75-4dc6-90ef-7488a7488082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preds(y_true, y_preds):\n",
    "    \"\"\"\n",
    "    Performs evaluation comparison on y_true labels vs. y_pred labels on a classification\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_preds)\n",
    "    precision = precision_score(y_true,  y_preds)\n",
    "    recall = recall_score(y_true, y_preds)\n",
    "    f1 = f1_score(y_true, y_preds)\n",
    "    metric_dict = {\"accuracy\": round(accuracy, 2),\n",
    "                   \"precision\": round(precision,2),\n",
    "                   \"recall\": round(recall,2),\n",
    "                   \"f1\": round(f1,2)}\n",
    "    print(f\"Acc: {accuracy* 100:2f}%\")\n",
    "    print(f\"Precision: {precision: .2f}\")\n",
    "    print(f\"Recall: {recall:2f}\")\n",
    "    print(f\"F1 score: {f1: .2f}\")\n",
    "\n",
    "    return metric_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b850e05c-b61c-471c-8159-93bb578f86b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Shuffle the data\n",
    "heart_disease_shuffled = heart_disease.sample(frac=1)\n",
    "\n",
    "# Split into X & y\n",
    "X = heart_disease_shuffled.drop(\"target\", axis=1)\n",
    "y = heart_disease_shuffled[\"target\"]\n",
    "\n",
    "# Split the data into trian, validation & test sets\n",
    "train_split = round(0.7 * len(heart_disease_shuffled)) # 70 % of data\n",
    "valid_split = round(train_split + 0.15* len(heart_disease_shuffled)) # 15% of data\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_valid, y_valid = X[train_split:valid_split],y[train_split:valid_split]\n",
    "X_test, y_test = X[valid_split:],y[:valid_split]\n",
    "\n",
    "# len(X_train), len(X_valid), len(X_test)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make baseline predictions\n",
    "y_preds = clf.predict(X_valid)\n",
    "\n",
    "# Evaluate the classifier on validation set\n",
    "baseline_metrics = evaluate_preds(y_valid, y_preds)\n",
    "baseline_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2335bcd6-1261-44bb-907d-afab83c3dfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Create a second classifier with different hyperparameters\n",
    "clf_2 = RandomForestClassifier(n_estimators = 100)\n",
    "clf_2.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction with different hyperparameters\n",
    "y_preds_2 = clf_2.predict(X_valid)\n",
    "\n",
    "# Evaluate the 2nd classifier\n",
    "clf_2_metrics = evaluate_preds(y_valid, y_preds_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821826bd-9458-47a3-880e-068da4ef3585",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_3 = RandomForestClassifier(n_estimators=100,\n",
    "                               max_depth=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8a184c-1ba2-4f6d-8e53-53f2bf14e383",
   "metadata": {},
   "source": [
    "### 5.2 Hyperparameter tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f36ea9c-13ca-4781-a77c-cdda3ffce21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "grid = {\"n_estimators\" : [10,100,200,500,1000,1200],\n",
    "        \"max_depth\": [None,5,10,20,30],\n",
    "        \"max_features\": [\"auto\",\"sqrt\"],\n",
    "        \"min_samples_split\": [2,4,6],\n",
    "        \"min_samples_leaf\": [1,2,4]}\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split into X & y\n",
    "X = heart_disease_shuffled.drop(\"target\",axis=1)\n",
    "y = heart_disease_shuffled[\"target\"]\n",
    "\n",
    "# Split into trian and test sets\n",
    "X_train,X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "# Instantiate RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_jobs=1)\n",
    "\n",
    "# Setup RandomizedSearchCV\n",
    "rs_clf = RandomizedSearchCV(estimator=clf,\n",
    "                            param_distributions=grid,\n",
    "                            n_iter=10, # number of models to try\n",
    "                            cv=5,\n",
    "                            verbose=2)\n",
    "\n",
    "# Fit the RandomizedSearchCV version of clf\n",
    "rs_clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867fc74f-0614-4013-af3a-aff9f3cab134",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbee30f7-e694-43eb-aec9-f26a9dec71a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make perdictions with the best hyperparamters\n",
    "rs_y_preds = rs_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the predictions\n",
    "rs_metrics = evaluate_preds(y_test, rs_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72d7895-00e4-46b7-87d1-6441944e25f7",
   "metadata": {},
   "source": [
    "### 5.3 Hyperparameter tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154dc1fc-ef4f-41dc-b6a1-32b137270471",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f646c0a-77bb-4083-89c4-8db9e93785f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_2 = {'n_estimators': [100, 200, 500 ],\n",
    "          'max_depth': [None],\n",
    "          'max_features': ['auto', 'sqrt'],\n",
    "          'min_samples_split': [6],\n",
    "          'min_samples_leaf': [1, 2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35481ec0-90b3-4588-9698-f1c0d8071041",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split into X & y\n",
    "X = heart_disease_shuffled.drop(\"target\",axis=1)\n",
    "y = heart_disease_shuffled[\"target\"]\n",
    "\n",
    "# Split into trian and test sets\n",
    "X_train,X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "# Instantiate RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_jobs=1)\n",
    "\n",
    "# Setup GridSearchCV\n",
    "gs_clf = GridSearchCV(estimator=clf,\n",
    "                      param_grid=grid_2,\n",
    "                      cv=5,\n",
    "                      verbose=2)\n",
    "\n",
    "# Fit the GridSearchCV version of clf\n",
    "gs_clf.fit(X_train, y_train);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8bcf6d-0592-4f24-b2c5-b5412d459404",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7aa636-2a53-4147-9cac-389f4685dc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_y_preds = gs_clf.predict(X_test)\n",
    "\n",
    "# evaluate the predictions\n",
    "gs_metrics = evaluate_preds(y_test, gs_y_preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3130e58-809b-469d-822d-f171bd304788",
   "metadata": {},
   "source": [
    "Let's compare our different models metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37d8c3b-9740-44fe-8141-4d67b9b70372",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_metrics = pd.DataFrame({\"baseline\": baseline_metrics,\n",
    "                               \"clf_2\":clf_2_metrics,\n",
    "                                \"random search\": rs_metrics,\n",
    "                                 \"grid search\": gs_metrics})\n",
    "\n",
    "compare_metrics.plot.bar(figsize=(10,8));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3a6c6c-6669-4580-884a-95c15b672d69",
   "metadata": {},
   "source": [
    "### 6. Saving and loading trained machine learning models\n",
    "\n",
    "Two ways to save and load machine learning models: \n",
    "1. With Python's `pickle` module\n",
    "2. With the `joblib` module\n",
    "\n",
    "**Pickle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c2aed5-39d4-4a19-b466-5dc6f27813b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save and existing model to file\n",
    "pickle.dump(gs_clf, open(\"gs_random_random_forest_model_1.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b39ad9-f787-4d4b-aba4-4a4a5c30e121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a saved model\n",
    "loaded_pickle_model = pickle.load(open(\"gs_random_random_forest_model_1.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6871db06-a552-4dc3-8a32-6f303f1deedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some perdictions\n",
    "pickle_y_preds = loaded_pickle_model.predict(X_test)\n",
    "evaluate_preds(y_test, pickle_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa96587-8d11-4dc8-a6f9-6960f1e81e97",
   "metadata": {},
   "source": [
    "**Joblib**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6727b299-baff-4b5f-a54f-8223f5367b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# Save model to file\n",
    "dump(gs_clf, filename=\"gs_random_forest_model_1.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c48686-32ae-44b7-b0d9-519ae20cc6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a saved joblib model\n",
    "loaded_joblib_model = load(filename = \"gs_random_forest_model_1.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0db3435-70c1-4932-81c6-3f94d4d0782d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make and evaluate joblib perdictions\n",
    "joblib_y_preds = loaded_joblib_model.predict(X_test)\n",
    "evaluate_preds(y_test, joblib_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c44dd69-963d-4ad0-8940-749b215f326b",
   "metadata": {},
   "source": [
    "### 7 Putting it all together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6292862b-c37a-4b6e-af5d-7f21c60ca4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/car-sales-extended-missing-data.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cc79ea-9bf6-49c6-a98f-3b807b5268f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb5c05e-6b1f-4d09-b638-dd63f255d6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b5f6c1-0698-4fe7-b96e-4028a8792f47",
   "metadata": {},
   "source": [
    "Steps we want to do (all in one cell):\n",
    "\n",
    "1. Fill misssing data\n",
    "2. Convert data to numbers\n",
    "3. Build a model on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e30e1a-be20-4257-a1ab-efa574d8a9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting data ready\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Modelling\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Setup random seed\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# Import data and drop rows with missing labels\n",
    "data = pd.read_csv(\"data/car-sales-extended-missing-data.csv\")\n",
    "data.dropna(subset=[\"Price\"], inplace=True)\n",
    "\n",
    "# Define different features and transformer pipeline\n",
    "categorical_features = [\"Make\", \"Colour\"]\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "door_feature = [\"Doors\"]\n",
    "door_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=4))\n",
    "])\n",
    "\n",
    "numeric_features = [\"Odometer (KM)\"]\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\"))\n",
    "])\n",
    "\n",
    "# Setup preprocessing steps (fill missing values, then convert to numbers)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "        (\"door\", door_transformer, door_feature),\n",
    "        (\"num\", numeric_transformer, numeric_features)\n",
    "    ])\n",
    "\n",
    "# Creating a preprocessing and modelling pipeline \n",
    "model = Pipeline(steps=[(\"preprocessor\", preprocessor),\n",
    "                        (\"model\", RandomForestRegressor())])\n",
    "\n",
    "# Split data\n",
    "X = data.drop(\"Price\", axis=1)\n",
    "y = data[\"Price\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Fit and score the model\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7963a606-06e0-4ee1-802f-c5a36d1c15f8",
   "metadata": {},
   "source": [
    "It's also possible to use `GridSearchCV` or `RandomizedSearchCV` with our `Pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb4834b-d4d6-4269-bc0a-71737e4b668f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GridSearchCV with our regression Pipeline\n",
    "pipe_grid = {\n",
    "    \"preprocessor__num__imputer__strategy\": [\"mean\", \"median\"],\n",
    "    \"model__n_estimators\": [100, 1000],\n",
    "    \"model__max_features\": [\"sqrt\", \"log2\"],\n",
    "    \"model__min_samples_split\": [2, 4]\n",
    "}\n",
    "\n",
    "gs_model = GridSearchCV(model, pipe_grid, cv=5, verbose=2)\n",
    "gs_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae89b3e1-1e25-4cfb-94c5-08a058d4bf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06f95b3-c6a8-4a9b-940a-c92fdc4a6428",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
